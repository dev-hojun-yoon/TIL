# 25. 8. 27 (Wed)

* 머신러닝
  * Soft voting 이 Hard voting 보다 성능이 좋은 경우가 일반적임
  * 앙상블 기법: 모델을 결합하여 성능을 높임
    * Bagging / Boosting : Bagging 은 병렬 / Boosting 은 순차 처리
      * Bagging : 부트스트랩 (샘플데이터를 재추출하여 통계적 추정치의 정확도/신뢰도를 높임) 이 over-fitting 을 줄이는 데 사용
        * Random Forest
      * Boosting
        * 경사하강법에 기반하여 부스팅
        * 오분류된 개체들에 대한 가중치를 높인다
        * 과적합이 bagging 보다 많이 발생할 수 있다.
  * AutoML 에 데이터를 넣고, 어떤 모델이 성능이 좋은지를 알아본다.
    * 다양한 모델 비교를 하기 때문에 무겁다 -> 여러가지 툴을 사용
    * 하이퍼파라미터 서치를 할 때에는 'Optuna' 혹은 'Lay' 사용 (AutoML 패키지)
      * 기본적으로는 RandomizedSearchCV
  * 다중 공산성: 통계학, 특히 회귀 분석에서 독렵 변수들 간에 강한 선형 관계가 존재하는 현상 // 즉, 하나의 독립변수가 다른 여러 개의 독립변수들로 잘 예측되는 경우
    * 이 경우 단순 선형 회귀 (OLS) 는 불안정한 해를 낼 수 있기 때문에, Ridge / Lasso 비교 실험을 한다.
  * AutoML: pycaret
  * 회귀 모델을 위한 평가 지표
    * R Square Score (결정 계수 - Coefficient of Determination)
      <img width="833" height="412" alt="image" src="https://github.com/user-attachments/assets/a0d9e063-4fa9-42dd-a1a1-e5b717dbc459" />
      * LaTeX 문법
        * y_i (아래 첨자): 실제 관측값
        * \hat{y} (y 위에 ^ 표시): 모델이 예측한 값
        * \bar{y} (y 위에 - 표시): 평균값
        * \sum (y_i - \hat{y}_i)^2: 잔차 제곱함 (RSS)
          * 실제값과 예측값의 차이의 제곱합
        * \sum (y_i - \bar{y})^2 : 총 제곱합 (TSS)
          * 실제값이 평균으로부터 흩어진 정도 (데이터 변동성)
        * RSS / TSS : 오차 크기를 원래 변동 크기와 비교 비율
        * 1 - RSS / TSS : 전체 변동 중에서 모델이 설명한 부분의 비율
        * 기준선은 baseline 으로 모든 샘플을 데이터의 평균 \bar{y} 으로 예측
        * 이 때 생기는 총 오차가 TSS 이고, 내 모델 예측이 만든 오차가 RSS 인 것이다.
        * 결정 계수는 모델의 오차가 기준선 오차 TSS 보다 얼마나 줄었는지 비율
        * 결정 계수가 1이면 완벽 예측, 0 이면 모델이 평균 정도 예측
        * 0보다 작으면 모델 예측이 기준선보다 커서 평균보다 못한 게 되는 것임.
    * MSE (Mean Squared Error, 평균제곱오차)
      <img width="508" height="280" alt="image" src="https://github.com/user-attachments/assets/13009ab6-84bc-474a-848e-91508cf7de1b" />
      * 단순 차이를 평균 내면 +, - 기호에 의해 상쇄되므로 제곱을 통해 모두 양수로 바꿔, 예측이 실제와 얼마나 차이가 나는지 명확히 알려줌.
      * 제곱을 통해서 큰 오차에 대해서는 영향이 더 커짐. (큰 실수를 줄이는 것에 초점)
      * 미분이 쉬워서 경사하강법 최적화 알고리즘에서 손실 함수로 자주 사용됨.
      * 즉 회귀 모델이 얼마나 정확한지, 큰 오차를 줄이고 있는지 평가 지표
    * RMSE: MSE 에 Root 를 씌운 것
      * 제곱근을 취해 원래 단위로 돌려놓음 -> 직관적 해석이 가능
    * MAE (Mean Absolute Error, 평균절대오차)
      <img width="817" height="345" alt="image" src="https://github.com/user-attachments/assets/4073376a-0355-429a-92ae-71ff4a1a8dd2" />
      * 예측과 실제 차이를 절대값으로 평균
      * MSE / RMSE 와 비교해 큰 오차를 과도하게 부각되지 않게함
    * MAPE (Mean Absolute Percentage Error, 평균절대백분율오차)
      <img width="829" height="356" alt="image" src="https://github.com/user-attachments/assets/44052e1f-333c-4be2-848e-f2c2935fa019" />
      * 평균 상대 오차
      * 단위가 없어 비교 쉬움

* 기타
  * Auto ML 중 MLxtend 도 있음
