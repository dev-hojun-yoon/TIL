# 25. 8. 29 (Fri)

* 머신러닝
  * fit 과 transform
    * fit(X): 입력 데이터 X 로부터 열별 μ (평균) 와 σ (표준편차) 를 학습/계산해서 scaler.mean_, scaler.scale_ 등에 저장
    * transform(x): 저장된 μ (평균) 와 σ (표준편차) 를 사용해 z-score 정규화를 계산하는 방식
    * fit_transform(x) : fit 한 뒤 바로 transform 까지 수행
    * fit 은 훈련 데이터만 (train) 적용하고 검증/테스트 데이터는 transform 만 적용해야 한다.
    * 테스트 데이터를 fit (스케일 계산) 하면 변환 결과와 모델 입력에 직접 영향을 줘서 성능 평가를 과장 (왜곡) 해서 일반화 성능을 잘못 추정함 -> 이게 데이터 누수이다.
  * sklearn.pipeline.Pipeline
    * 모델 훈련 및 하이퍼파라미터 탐색 단순화 (GridSearch 등)
      * 데이터 전처리 → 특징 추출 → 모델 학습 과정을 하나의 흐름으로 묶어줌.
        * GridSearchCV 같은 튜닝 도구에서 파라미터를 바꿀 때, 파이프라인 안의 스텝에 대해 일관성 있게 최적화
        * 예) 스케일러(StandardScaler)와 분류기(RandomForestClassifier)를 파이프라인에 묶으면, GridSearchCV에서 스케일링과 모델을 동시에 최적화할 수 있음
    * 서빙(실제 서비스 적용) 시 로직 단순화
      * 예측할 때도 전처리 과정을 거쳐야 하는데 파이프라인을 쓰면 "학습 시 적용한 전처리"와 동일한 절차를 자동으로 보장
        * pipeline.predict(X_new) 한 줄이면 전처리 → 특징 변환 → 모델 예측까지 한 번에 수행
    * 따라서 운영/서빙 시에 로직이 간단해지고 일관성이 확보됩니다.
  * 서빙 (Serving) & 예측 (Inference / Prediction)
    * 정리하면, Inference 는 모델이 예측하는 행위이고, Serving 은 그 예측 기능을 외부에 제공하는 운영 환경이다.
    * 서빙
      * 모델을 실제 환경에서 서비스로 배포해 요청(Request)을 받고 응답(Response)을 주는 구조
      * 예: REST API, gRPC, 메시지 큐 기반으로 모델을 띄워놓고, 사용자 입력이 오면 예측값을 반환하는 시스템.
      * 즉, 모델을 외부에서 쓸 수 있도록 “서비스화” 하는 행위
    * 예측
      * 즉, 모델을 외부에서 쓸 수 있도록 “서비스화” 하는 행위
      * model.predict(X_test)
      * 내부에서 단순히 함수 호출도 가능하고, 서비스로 제공되는 환경에서 호출 가능
  * 군집화
    * K-Means 유클리드 거리로 군집화, 원본값의 스케일 (단위, 분산)이 다르면 분산이 큰 특성으로 인해 군집이 왜곡되기 때문에, StandardScaler 는 각 열 (특성) 마다 평균 0, 표준편차 1로 맞춘다.
    * StandardScaler.fit_transform(...)의 반환값은 넘파이 배열이라 컬럼명/인덱스가 사라집니다.
    * 위 값을 Pandas Dataframe 로 바꾸면, 열 이름 / 인덱스 유지, 후처리 편의, 버그 방지 (넘파이 배열 상태는 열 순서가 바뀜) 의 효용이 있음 => Dataframe 로 변환하면 분석과 시각화가 가능하기 때문에 실용적이다.
