## 25. 7. 11 (Fri)

* Pandas (panel data system)
  * panel 은 그룹이란 뜻을 가지고 있음
  * 패널 데이터는 여러 개체들을 시간을 두고 추적하여 얻는 데이터
  * numpy 를 내부적으로 활용한다.
  * 엑셀과 같이 **인덱스 (index), 변수 (column), 값 (value)**
  * 데이터 접근법은 df = pd.DataFrame(data)
    * df['Name'][0] 변수 -> 인덱스
    * df.get('Name')
    * df.Name
    * type(df.Name) -> series.. 1차원 데이터를 관리하는 pandas 자료형
    * df -> series 여러개를 묶어서 관리하는 자료형
    * series 별로 data type 이 다를 수 있다.
  * df.columns : 열에 붙이는 이름
  * df.index : 행에 붙이는 이름
    * df.index += 1 시작 인덱스를 변경할 수 있다.
    * df.index = ['신짱구', '짱아', '훈이'] 로 인덱스 직접 변경할 수 있다.
  * df.values: 모든 데이터가 표시됨. 내부적으로는 ndarray 를 series 단위로 관리한다.
  * 숫자 자료형의 '값 없음은 np.nan 으로 관리된다.
  * del df['지역'] 해당 필드 삭제
    * df = df.drop('지역', axis=1)
  * df['지역'] = '상암' # 문자열의 broadcasting
  * data.head(1) // 앞에서 몇개를 볼 것이냐 (기본 5)
    * data.tail 과 비교
  * df2 = df.copy() # numpy 처럼 pandas 의 copy 도 deepcopy
    df2['Sex'] = data['Sex'] 이와 같은 방식으로 여러개도 가능하다.
  * df 를 합치기 위한 명령어
    * merge (중복되지 않는 것을 합침), concat(합침), join (조건을 걸어 합침)
    * pd.merge(df, data)
    * pd.concat((df, data), join='inner') # 둘다 가지고 있는 값으로 설정
    * join
      * pandas.DataFrame.join
        * df.join(data, rsuffix="_2") : 중복되는 컬럼/행의 이름을 어떻게 처리할 것인지
      * pandas.Index.join
      * pandas.Series.str.join
    * dataframe 은 열 -> 행 순서인데, 행 -> 열 순서로 특정 행, 원소에 접근하고 싶을 때
      * df.loc[0] 0번 행에 있는 정보
      * 인덱싱으로 행의 정보를 가져오기
        * data.loc[[0, 1]]
      * 슬라이싱
        * data.loc[0:1] 시작점과 끝점
      * data.loc[0:1, ['Age', 'Name']] # 인덱싱을 활용하면 원본 순서를 바꿔서 특정 데이터를 표시할 수 있음
      * 내부적으로 넘파이로 동작하므로 iloc (index location) 라는 명령어로 똑같은 위치를 순서로 호출
        * df.iloc[0:1, 0] # 행, 열 - 다른 배열을 다루는 방법처럼 슬라이싱 시 끝점 + 1로 동작
      * data2.loc[0:1, 'Age':'Score']
      * data2.loc[[0,1], ['Age', 'Score']]
      * data2.iloc[0:2, 1:3]
  * df.sort_values('Age')
    * df.sort_values(['Name', 'Age']) # 정렬의 우선순위 선정
  * data.Sex.replace('Male', 'M').replace('Female' 'F')
    * df.data.Sex.replace(['Male', 'Female'], ['M', 'F'], inplace=True)
  * 하나의 컬럼도 [] 를 넣으면 DataFrame 으로 변환된다.
    * type(df_jjang.loc[df_jjang.Age > 22, 'Name']) -> Series
    * type(df_jjang.loc[df_jjang.Age > 22, ['Name']])
    * 결과만 필요하면 Series 도 괜찮은데, 동작하지 않는 함수가 있어 dataframe 으로 바꿔주자.
  * pandas 값 조회 (예제)
    ```python
    df_jjang['Result'] = df_jjang.Score >= 80
    df_jjang.loc[df_jjang.Result == True, 'Result'] = 'Pass'
    df_jjang.loc[df_jjang.Result == False, 'Result'] = 'Fail'

    df_jjang.loc[df_jjang['Score'] >= 80, 'Result'] = 'Pass'
    df_jjang.loc[df_jjang['Score'] < 80, 'Result'] = 'Fail'

    df_jjang["Result"] = (df_jjang.Score >= 80).replace([True,False],["Pass", "Fail"])
    df_jjang['Result'] =  np.where(df_jjang.Score >= 80, 'Pass', 'Fail')
    ```
  * exporting to excel
    * df_jjang.to_excel("new_jjanggu.xlsx", index=False)
      * 인덱스 없이 저장
    * df_jjang.to_excel("new_jjanggu.xlsx") # 인덱스 포함해 저장
    * pd.read_excel('new_jjanggu.xlsx', index_col=0) # 0번 순서의 컬럼을 인덱스로 사용
    * df = pd.read_csv('/content/drive/MyDrive/test.csv')
  * 데이터 처리 시 확인하는 정보
    * df.info()
    * df.describe(include='all')
    * df.head()
    * df.tail()
  * 중복된 데이터 확인
    df.등록일자[df.등록일자.duplicated()]
    df[df.등록일자 == '2022-03-15']
    df.반.value_counts()

    보통 group by 를 많이 쓴다.
    df.groupby("묶음의 기준이 되는 컬럼명")["적용받는 컬럼"].적용받는 연산()
    df.groupby('반')[['이름', '번호']].count()

    type(df.groupby('반')['테스트점수'].sum()) => Series
    type(df.groupby('반')[['테스트점수']].sum()) => DataFrame

  * df.groupby("반")[['이름','테스트점수']].sum() # 자료형이 달라도 가능한 연산이면 결과가 출력
    * 짱아짱구아빠짱구엄마	218

  * 보기 편하게 다음과 같이 표현할 수 있음
    df.groupby(['반', '이름'])['테스트점수'].sum()

  * 짱구엄마의 테스트점수 원소
    df2 = df.groupby(['반', '이름'])[['테스트점수']].sum() # dataframe 으로 변환
    df2.index (개나리반 / HJ)
    df2.columns (테스트점수)
    df2.values
    df2.loc[('개나리', '짱구엄마'), '테스트점수']
    df2.iloc[1, 0]
    df2.reset_index()
    df3 = df2.reset_index(level=1) # 멀티인덱스에서 어느 레벨까지 인덱스를 컬럼화해서 사용할지 정하는 파라미터
    df3.loc['개나리'] # 중복되는 인덱스/컬럼으로는 여러개의 행을 한꺼번에 부를 수 있습니다.
    df3.iloc[1]

  * 2022-03-15 이후에 온 사람 리스트
    * df[df.등록일자 >= '2022-03-15']

  * datetime64라는 별도의 시간을 위한 자료형
    * df.등록일자 = df.등록일자.astype('datetime64[ns]')
    * datetime 모듈에서 timedelta object 는 day, second, 등 시간계산할 때 사용
   
  * 시간을 사용하기위한 python 모듈인 datetime과 호환
    * from datetime import datetime, timedelta
    * 시간 변화를 연산하기 위한 객체인 timedelta 로 시간 연산 가능
    * from datetime import datetime, timedelta
    * df.등록일자 = df.등록일자 + timedelta(days=365)
    * df = df.drop(['번호', '단위'], axis=1)
    * del df['번호']

  * melt 를 이용해 녹인다.
    * groupby 를 하기 위해 중간 과정에서 주로 사용한다.
    * df1.melt(id_vars=['store', 'product'])
    * df2 = df1.melt(id_vars=['store', 'product'], var_name='원래컬럼이었던값', value_name='실제값')
    * df2.groupby(['store', 'product', '원래컬럼이었던값', '실제값']).max()
    * melt()는 ID 변수를 하나 혹은 여러 개 지정해서 그것들을 기준으로 나머지 열의 이름과 열 값들을 아래로 쭉 나열하여 재구조화한다. melt()를 쓰면 얇고 긴 데이터프레임이 만들어 진다.

  * pivot
    * df1.pivot(index='store', columns='product')
    * pivot()이 인덱스와 행, 열을 하나하나 지정해서 데이터를 재구조화/보기 좋게 구축화하는 것

  * melt, pivot 을 사용해서 데이터를 더 보기 편하게
    * df1.groupby(['store','product'])[['price','quantity']].sum()
    * df1.pivot(index='store', columns='product').stack()
    * 수량당 가격(unit price) 계산
      * df1['unit_price'] = df1['price'] / df1['quantity']
    * store, product별 quantity와 unit_price를 피벗 테이블로 요약
      ```python
      pivot = pd.pivot_table(
          df1,
          index='store',
          columns='product',
          values=['quantity', 'unit_price']
      )
      ```
    * 보기 좋게 소수점 2자리로 반올림
      pivot = pivot.round(2)

    * 컬럼 순서 보기 좋게 정렬 (선택사항)
      pivot = pivot.reorder_levels([1,0], axis=1).sort_index(axis=1)

    * .sort_values(by=['store', 'price'], ascending=[True, False])
             # by=[1차기준, 2차기준], ascending=[1차기준, 2차기준]
       df1.groupby(['store', 'product'])[['price', 'quantity']].sum().sort_values(by=['store', 'price'], ascending=[True, False])

  * function apply (map 과 비슷한 역할)
    * 브로드캐스팅을 대신하여 모든 원소에 동일하게 적용하고 싶을 때 사용
    * df['분점6'] = df.반.apply(lambda x: '강서구' if x == '미나리' else ('강동구' if x == '개나리' else '광명시'))
    * df.테스트점수.apply(add_one)
    * df.apply(add_one2, axis=1)
   
  * filter - 컬럼명에서 원하는 문자/문자열을 쉽게 검색할 수 있습니다
    * df.filter(items=['이름', '테스트점수'])
    * df.filter(regex='이+')
    * df.filter(like='점') # 중간에 들어가는 글자도 포함
   
  * isin - 데이터에서 원하는 문자/문자열을 쉽게 검색할 수 있습니다
    * df.isin(['짱구'])
    * df[df.이름.isin(['짱구', '짱아'])] # 완전일치
    * df[df.이름.str.contains('짱')] # 일부일치
    * df[df.이름.str.contains('짱구')]
    * df[df.이름.str.startswith('짱')]
    * df[df.이름.str.contains('^..$')]
      * ^ 문자열의 시작
      * $ 문자열의 끝
      * .. 임의의 두글자
 
* 기타
  * 파생변수: 이미 있는 데이터를 특정 컬럼의 조건에 따라 새로 알고싶은 형태로 변경
  * 내장 파이썬의 명령어로 df 를 호출할 때는 bracket
  * data.info() // 자료구조를 알 수 있다.
  * data.describe() // 통계치, 대표값을 알 수 있다. 수집된 자료들의 경향성을 보여주는 대표값
    * data.describe(include=all) 모두 확인
  * inplace=True 파라미터가 있으면 원본이 수정되는 점을 기억
  * 22 < df.Age < 25 이런 표현은 안되고,
    * df[(22 < df.Age) && (df.Age < 25)]
  * pandas not ~ > and & > or | 의 우선순위
  * df.describe().T
    * 보기 편한 경우가 있음
